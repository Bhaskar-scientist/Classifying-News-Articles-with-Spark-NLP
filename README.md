# ğŸ“° Classifying News Articles with Spark NLP

Built a scalable **text classification model** using **Spark NLP**, **PySpark ML**, and **John Snow Labs' pre-trained models**. The project processes and classifies **2,225 BBC News articles** into **five categories**: `business`, `entertainment`, `politics`, `sport`, and `tech`.

---

## ğŸ“Œ Project Highlights

* ğŸ“„ **Dataset**: 2,225 labeled BBC news articles  
* ğŸ§  **Goal**: Accurately classify each article into one of the five categories  
* âš™ï¸ **Tech Stack**: PySpark, Spark NLP, Spark MLlib, Pandas, John Snow Labs NLP models, Google Cloud Platform (GCP)  
* ğŸ›  **Pipeline Includes**:
  * Data ingestion and cleaning
  * Text preprocessing (tokenization, lemmatization, stopwords removal, etc.)
  * Feature extraction (TF-IDF, CountVectorizer)
  * Model training using Spark ML algorithms
  * Evaluation using accuracy, F1-score, and precision/recall

---

## ğŸ§ª Tools & Libraries Used

* **Apache Spark & PySpark**: Distributed data processing  
* **Spark NLP (John Snow Labs)**: High-performance NLP on Spark  
* **Spark MLlib**: Scalable machine learning pipelines  
* **Google Cloud Platform (GCP)**: Cloud-native architecture suggestion  
* **Jupyter Notebook**: Interactive development environment

---

## ğŸŒ Suggested GCP Architecture

This architecture shows how the solution could scale in a real-world environment using GCP services:

![GCP Architecture](assets/gcp_architecture.png)

> Save the image as `assets/gcp_architecture.png` inside a folder named `assets` in your GitHub repository.

---

## ğŸ“ Repository Structure

ğŸ“¦ Classifying-News-Articles-with-Spark-NLP
â”£ ğŸ““ Spark NLP & ML for Text Classification.ipynb
â”£ ğŸ“œ README.md
â”— ğŸ“ assets
â”— ğŸ–¼ï¸ gcp_architecture.png

yaml
Copy
Edit

---

## ğŸ“ˆ Results

The trained models were able to achieve strong classification accuracy on the BBC News dataset. Spark NLP's integration with Spark ML pipelines enabled fast and efficient processing of text at scale.

---

## ğŸš€ Getting Started

### 1. Clone the Repo

``` 
git clone https://github.com/Bhaskar-scientist/Classifying-News-Articles-with-Spark-NLP.git
cd Classifying-News-Articles-with-Spark-NLP
```
2. Install Dependencies

pip install pyspark spark-nlp pandas

4. Launch Jupyter Notebook

jupyter notebook

Then open and run:
ğŸ““ Spark NLP & ML for Text Classification.ipynb

ğŸ” Future Improvements
Deploy the classifier using Streamlit or Flask

Add a REST API for real-time predictions

Experiment with more advanced models (e.g., BERT with Spark NLP)

Visualize word distributions and model confusion matrices

Integrate with Google Cloud Storage & Vertex AI

ğŸ‘¨â€ğŸ’» Author
Bhaskar Reddy
Data Scientist | NLP & ML Enthusiast
ğŸŒ ![LinkedIn]([assets/gcp_architecture.png](https://www.linkedin.com/in/bhaskar-reddy-challapureddy/)

â­ï¸ If you found this useful...
Feel free to star the repository and share it with others working in NLP or PySpark!
